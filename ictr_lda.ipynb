{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ictr_lda",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTyU4fEvTmuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f65a0cab-faf5-4980-bd8f-ef7bd3840532"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive/delicious_csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/delicious_csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRPvOoHGTil6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJAyn-yT5Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_embeddings = pd.read_csv(\"norm_matrix_ejml_full_delicious.csv\", header=None)\n",
        "item_embeddings.sort_values(0, inplace=True)\n",
        "book = pd.read_csv(\"bookmarks.csv\")\n",
        "book_tags = pd.read_csv(\"bookmark_tags.csv\")\n",
        "tags = pd.read_csv(\"tags.csv\")\n",
        "user_contacts = pd.read_csv(\"user_contacts.csv\")\n",
        "user_contacts_t = pd.read_csv(\"user_contacts-timestamps.csv\")\n",
        "user_taggedb = pd.read_csv(\"user_taggedbookmarks.csv\")\n",
        "user_taggedbt = pd.read_csv(\"user_taggedbookmarks-timestamps.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLcbfpmUQDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_item = {idx: item for idx, item in enumerate(item_embeddings[0].to_list())}\n",
        "item_set = set(item_embeddings[0].to_list())\n",
        "item_to_idx = {v: k for k, v in idx_to_item.items()}\n",
        "idx_to_user = {idx: user for idx, user in enumerate(sorted(list(set(user_taggedb['userID']))))}\n",
        "user_to_idx = {v: k for k, v in idx_to_user.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDEqkJ40UXx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_to_book = []\n",
        "for idx, user in idx_to_user.items():\n",
        "  user_to_book.append((user, sorted(list(set(user_taggedb[user_taggedb[\"userID\"] == user][\"bookmarkID\"])))))\n",
        "user_to_items = {user: items for user, items in user_to_book}\n",
        "pca = item_embeddings.iloc[:, 1:].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DP6ENgoHi5S",
        "colab_type": "text"
      },
      "source": [
        "Here, we'll try reproducing the algorithm in \"Online Interactive Collaborative Filtering Using Multi-Armed Bandit with Dependent Arms\", which is an LDA-based clustering algorithm as per the algorithm mentioned.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l8V-hF-HhxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_particles = 10\n",
        "num_items = pca.shape[0]\n",
        "D = pca.shape[1]\n",
        "K = D # Number of topics (or clusters) is forced to be equal to PCA dimension,\n",
        "      # since we're not generating feature vectors\n",
        "num_users = len(idx_to_user)\n",
        "num_contexts = 25\n",
        "\n",
        "# Hyperparameters\n",
        "eta = np.ones(num_items) #/ num_items\n",
        "lamda = np.ones(K) #/ K\n",
        "alpha = 1\n",
        "beta = 1\n",
        "# The below are irrelevant due to above\n",
        "# mu_q = np.zeros(D)\n",
        "# Sigma_q = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCxGKkyBHheE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "particles = []\n",
        "for _ in range(num_particles):\n",
        "  particle = {\"eta\": eta, \"lambda\": lamda, \"alpha\": alpha, \"beta\": beta}\n",
        "  particle.update({\"sigma\": np.reciprocal(np.random.gamma(particle[\"alpha\"], 1 / particle[\"beta\"], num_items))})\n",
        "  particle.update({\"p\": np.random.dirichlet(particle[\"lambda\"], size=num_users)})\n",
        "  particle.update({\"phi\": np.random.dirichlet(particle[\"eta\"], size=K)})\n",
        "  particle.update({\"z\": np.array([np.random.multinomial(1, particle[\"p\"][i, :]) for i in range(num_users)])})\n",
        "  particles.append(particle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhmfVcjykVdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d45bc6-ae58-479d-c55e-c19d6e29643e"
      },
      "source": [
        "T = 100000\n",
        "cu_r = 0.0\n",
        "for t in range(T):\n",
        "  if t % 500 == 0:\n",
        "    print(t, cu_r)\n",
        "  u = np.random.choice(num_users)\n",
        "  #print(particles[0][\"eta\"])\n",
        "  av_rewards, r_rewards, item_idxs = evaluate(u, particles)\n",
        "  #print(particles[0][\"eta\"])\n",
        "  s = np.argmax(av_rewards)\n",
        "  r = r_rewards[s]\n",
        "  s = item_idxs[s]\n",
        "  cu_r += r\n",
        "  update(u, s, r, particles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.0\n",
            "500 29.0\n",
            "1000 52.0\n",
            "1500 78.0\n",
            "2000 107.0\n",
            "2500 125.0\n",
            "3000 152.0\n",
            "3500 183.0\n",
            "4000 205.0\n",
            "4500 242.0\n",
            "5000 263.0\n",
            "5500 292.0\n",
            "6000 315.0\n",
            "6500 344.0\n",
            "7000 368.0\n",
            "7500 390.0\n",
            "8000 411.0\n",
            "8500 429.0\n",
            "9000 460.0\n",
            "9500 495.0\n",
            "10000 517.0\n",
            "10500 544.0\n",
            "11000 567.0\n",
            "11500 603.0\n",
            "12000 629.0\n",
            "12500 650.0\n",
            "13000 677.0\n",
            "13500 706.0\n",
            "14000 726.0\n",
            "14500 753.0\n",
            "15000 782.0\n",
            "15500 817.0\n",
            "16000 846.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaxNWWA4pHjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_contexts(user_idx, num_contexts):\n",
        "  user = idx_to_user[user_idx]\n",
        "  items = user_to_items[user]\n",
        "  items_idx = np.array([item_to_idx[item] for item in items if item in item_set])\n",
        "\n",
        "  good_item_idx = np.random.choice(items_idx, 1)\n",
        "  good_item_context = pca[good_item_idx]\n",
        "  bad_items_idx = np.random.choice(np.setdiff1d(range(num_items), items_idx), num_contexts - 1, replace=False) \n",
        "  bad_items_contexts = pca[bad_items_idx]\n",
        "    \n",
        "  contexts = np.vstack((good_item_context, bad_items_contexts))\n",
        "  rewards = np.array([1] + (num_contexts - 1) * [0]) #-1/(num_contexts - 1)])\n",
        "  idxs = np.concatenate((good_item_idx, bad_items_idx))\n",
        "\n",
        "  return contexts, rewards, idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooQWo2YzlbBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(u, particles):\n",
        "  cu_rewards = np.zeros(num_contexts)\n",
        "  for particle in particles:\n",
        "    p = particle[\"p\"][u, :]\n",
        "    item_feats, r_rewards, item_idxs = get_contexts(u, num_contexts)\n",
        "    for i in range(item_feats.shape[0]):\n",
        "      cu_rewards[i] += np.random.normal(item_feats[i, :]@p, particle[\"sigma\"][item_idxs[i]])\n",
        "  av_rewards = cu_rewards / len(particles)\n",
        "  return av_rewards, r_rewards, item_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arBATVp1BDv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update(u, s, r, particles):\n",
        "  weights = np.zeros(len(particles))\n",
        "  for idx, particle in enumerate(particles):\n",
        "    # Review - seems to be some error in the paper\n",
        "    # for k in range(K): # todo - vectorize\n",
        "    #  weights[idx] += (1 / (2 * np.pi * particle[\"sigma\"][s])**0.5) * np.exp(-(r - particle[\"p\"][u, :]@pca[s, :])**2) \n",
        "    #              * (particle[\"p\"][u, k] / np.sum(particle[\"p\"][u, :])) * (particle[\"phi\"][k, s] / np.sum(particle[\"phi\"][k, :]))\n",
        "    weights[idx] += (1 / (2 * np.pi * particle[\"sigma\"][s])**0.5) * np.exp(-(r - particle[\"p\"][u, :]@pca[s, :])**2/(2 * particle[\"sigma\"][s])) * (particle[\"eta\"][s] / np.sum(particle[\"eta\"]))\n",
        "  weights /= np.sum(weights)\n",
        "  for idx, particle in enumerate(particles):\n",
        "    flag = np.random.binomial(1, weights[idx])\n",
        "    if flag == 0:\n",
        "      continue\n",
        "    else:\n",
        "      particle[\"sigma\"] = np.reciprocal(np.random.gamma(particle[\"alpha\"], 1 / particle[\"beta\"], num_items))\n",
        "      particle[\"p\"] = np.random.dirichlet(particle[\"lambda\"], size=num_users)\n",
        "      particle[\"phi\"] = np.random.dirichlet(particle[\"eta\"], size=K)\n",
        "      particle[\"z\"] = np.array([np.random.multinomial(1, particle[\"p\"][i, :]) for i in range(num_users)])\n",
        "  for particle in particles:\n",
        "    # Sufficient statistics for z\n",
        "    e_p = (particle[\"z\"][u, :].copy() * r + particle[\"lambda\"].copy())\n",
        "    e_p /= np.sum(e_p)\n",
        "    e_phi = particle[\"eta\"].copy()\n",
        "    e_phi[s] += r\n",
        "    e_phi /= np.sum(e_phi)\n",
        "    theta = (e_p.copy() * e_phi[s])\n",
        "    theta /= np.sum(theta)\n",
        "    # Resample z as per new posterior\n",
        "    particle[\"z\"][u, :] = np.random.multinomial(1, theta)\n",
        "    # print(particle[\"z\"][u, :])\n",
        "    # Update sufficient statistics\n",
        "    particle[\"alpha\"] += 0.5\n",
        "    particle[\"beta\"] += 0.5 * r**2\n",
        "    particle[\"lambda\"] += particle[\"z\"][u, :] * r\n",
        "    # print(particle[\"lambda\"]) \n",
        "    particle[\"eta\"][s] += r\n",
        "    # print(particle[\"eta\"][s], particle[\"eta\"])\n",
        "    # Resample everything\n",
        "    particle[\"sigma\"] = np.reciprocal(np.random.gamma(particle[\"alpha\"], 1 / particle[\"beta\"], num_items))\n",
        "    particle[\"p\"] = np.random.dirichlet(particle[\"lambda\"], size=num_users)\n",
        "    particle[\"phi\"] = np.random.dirichlet(particle[\"eta\"], size=K)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}